{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gix6ifxKSef0"
      },
      "outputs": [],
      "source": [
        "# Установка Airflow\n",
        "!pip install apache-airflow==2.1.4\n",
        "\n",
        "# Инициализация базы данных\n",
        "!airflow db init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим необходимые папки\n",
        "!mkdir /root/airflow/dags\n",
        "!touch /root/airflow/dags/dag.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e35kla8BSgBp",
        "outputId": "d5c480f3-e0e5-4840-f59c-b5782f6d6475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/airflow/dags’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Включим веб-сервер\n",
        "!airflow webserver -p 18273 -D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2cWbBV0Si5C",
        "outputId": "874ae076-0e6d-4acd-c1ec-b8894d714d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
            "[\u001b[34m2023-04-07 13:07:59,981\u001b[0m] {\u001b[34mdagbag.py:\u001b[0m496} INFO\u001b[0m - Filling up the DagBag from \u001b[01m/dev/null\u001b[22m\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/airflow\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/airflow/__main__.py\", line 40, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/airflow/cli/cli_parser.py\", line 48, in command\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/airflow/utils/cli.py\", line 92, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/airflow/cli/commands/webserver_command.py\", line 368, in webserver\n",
            "    check_if_pidfile_process_is_running(pid_file=pid_file, process_name=\"webserver\")\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/airflow/utils/process_utils.py\", line 267, in check_if_pidfile_process_is_running\n",
            "    raise AirflowException(f\"The {process_name} is already running under PID {pid}.\")\n",
            "airflow.exceptions.AirflowException: The webserver is already running under PID 1079.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим пользователя Airflow\n",
        "!airflow users create \\\n",
        "          --username admin \\\n",
        "          --firstname admin \\\n",
        "          --lastname admin \\\n",
        "          --role Admin \\\n",
        "          --email admin@example.org \\\n",
        "          -p 12345"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o6TeWetSnhZ",
        "outputId": "32fa4166-16b0-44cb-d593-b18dc7b58236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "admin already exist in the db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск шедулера\n",
        "!airflow scheduler -D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1mmwb7bSorO",
        "outputId": "3b1c2b12-2c6e-4fd1-c714-364e6713314c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/airflow/utils/\u001b[0m\u001b[1;33mcli.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m149\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/airflow/utils/\u001b[0m\u001b[1;33mcli.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m149\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Последующие команды не имеют отношения к Airflow\n",
        "# Они нужни только для корректной работы веб морды\n",
        "# в среде Google Colab\n",
        "\n",
        "!pip install pyngrok\n",
        "!ngrok authtoken '2NssWBxpPPT0Yj7i2gGK09ZslOI_7FfHuY7vh9tfyDWaDNT2z' # найти его можно https://dashboard.ngrok.com/get-started/setup \n",
        "\n",
        "# Эта команда просто отображет веб морду на другой адрес\n",
        "# Его вы можете найти https://dashboard.ngrok.com/cloud-edge/status\n",
        "# При каждом отключении ссылка будет меняться\n",
        "!nohup ngrok http -log=stdout 18273 > /dev/null &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ-MWhVtSsMF",
        "outputId": "11586cda-b83e-41ce-9c77-f5e8ee51ee66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.9/dist-packages (5.2.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyngrok) (6.0)\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "nohup: redirecting stderr to stdout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from airflow import DAG\n",
        "from datetime import timedelta\n",
        "from airflow.utils.dates import days_ago\n",
        "from airflow.operators.python import PythonOperator\n",
        "from jinja2 import Template\n",
        "\n",
        "def jinja(x):\n",
        "  x = int(x)\n",
        "  t = Template(\"{% for i in range(1, x) if i%2 == 0 %}{{i}} {% endfor %}\")\n",
        "  print(t.render(x=x))\n",
        "\n",
        "dag = DAG('dag',schedule_interval=timedelta(days=1), start_date=days_ago(1))\n",
        "\n",
        "def print_context(**context):\n",
        "    context['ti'].xcom_push(key='context_len', value=str(len(context)))\n",
        "\n",
        "run_this = PythonOperator(\n",
        "    task_id='print_the_context',\n",
        "    python_callable=print_context,\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "ji = PythonOperator(\n",
        "    task_id='print_ji',\n",
        "    python_callable=jinja,\n",
        "    op_kwargs={'x': 10},\n",
        "    dag=dag,\n",
        ")"
      ],
      "metadata": {
        "id": "4lGqVNPUSvCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}