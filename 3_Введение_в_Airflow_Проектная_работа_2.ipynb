{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWPt10Qnplbl"
      },
      "source": [
        "### Настройка Airflow\n",
        "\n",
        "Для начала вам необходимо выполнить ряд команд чтобы настроить окружение для дальнейшей работы, это позволит первое время не заниматься настройкой среды исполнения, а сразу начать писать код и работать с Airflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ8FIAohplbm",
        "outputId": "2fbcc448-6fe3-404b-f012-c3840a33ba1b"
      },
      "outputs": [],
      "source": [
        "# Установка Airflow\n",
        "!pip install apache-airflow==2.1.4\n",
        "\n",
        "# Инициализация базы данных\n",
        "!airflow db init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxU7z0bWplbr"
      },
      "outputs": [],
      "source": [
        "# Создадим необходимые папки\n",
        "!mkdir /root/airflow/dags\n",
        "!touch /root/airflow/dags/dag.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcUWe4bcplbr",
        "outputId": "4c9ebc75-31ff-4481-81cf-72d0b579ea8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
            "[\u001b[34m2023-04-19 09:12:35,385\u001b[0m] {\u001b[34mdagbag.py:\u001b[0m496} INFO\u001b[0m - Filling up the DagBag from \u001b[01m/dev/null\u001b[22m\u001b[0m\n",
            "[\u001b[34m2023-04-19 09:12:35,449\u001b[0m] {\u001b[34mmanager.py:\u001b[0m805} \u001b[33mWARNING\u001b[0m - \u001b[33mNo user yet created, use flask fab command to do it.\u001b[0m\n",
            "Running the Gunicorn Server with:\n",
            "Workers: 4 sync\n",
            "Host: 0.0.0.0:18273\n",
            "Timeout: 120\n",
            "Logfiles: - -\n",
            "Access Logformat: \n",
            "=================================================================            \n"
          ]
        }
      ],
      "source": [
        "# Включим веб-сервер\n",
        "!airflow webserver -p 18273 -D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdYWfifpplbs",
        "outputId": "bf30b388-d628-4c24-d73c-274939f87420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "[\u001b[34m2023-04-19 09:12:48,180\u001b[0m] {\u001b[34mmanager.py:\u001b[0m805} \u001b[33mWARNING\u001b[0m - \u001b[33mNo user yet created, use flask fab command to do it.\u001b[0m\n",
            "Admin user admin created\n"
          ]
        }
      ],
      "source": [
        "# Создадим пользователя Airflow\n",
        "!airflow users create \\\n",
        "          --username admin \\\n",
        "          --firstname admin \\\n",
        "          --lastname admin \\\n",
        "          --role Admin \\\n",
        "          --email admin@example.org \\\n",
        "          -p 12345"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oVdLIkplbs"
      },
      "source": [
        "Поместите в dag.py следующий код.\n",
        "\n",
        "```python\n",
        "from airflow import DAG\n",
        "from datetime import timedelta\n",
        "from airflow.utils.dates import days_ago\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "\n",
        "dag = DAG('dag',schedule_interval=timedelta(days=1), start_date=days_ago(1))\n",
        "t1 = DummyOperator(task_id='task_1', dag=dag)\n",
        "t2 = DummyOperator(task_id='task_2',dag=dag)\n",
        "t3 = DummyOperator(task_id='task_3',dag=dag)\n",
        "t4 = DummyOperator(task_id='task_4',dag=dag)\n",
        "t5 = DummyOperator(task_id='task_5',dag=dag)\n",
        "t6 = DummyOperator(task_id='task_6',dag=dag)\n",
        "t7 = DummyOperator(task_id='task_7',dag=dag)\n",
        "\n",
        "[t1, t2]>>t5\n",
        "t3>>t6\n",
        "[t5,t6] >>  t7\n",
        "t4\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7yIZoaGplbs",
        "outputId": "88824315-d96d-41d1-cd85-18a79a24b3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/airflow/utils/\u001b[0m\u001b[1;33mcli.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m149\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.9/dist-packages/airflow/utils/\u001b[0m\u001b[1;33mcli.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m149\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n"
          ]
        }
      ],
      "source": [
        "# Запуск шедулера\n",
        "!airflow scheduler -D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ttHjsvjplbt",
        "outputId": "d2992068-5405-465a-bf6c-d2904419f243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.9/dist-packages (6.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyngrok) (6.0)\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# Последующие команды не имеют отношения к Airflow\n",
        "# Они нужни только для корректной работы веб морды\n",
        "# в среде Google Colab\n",
        "\n",
        "!pip install pyngrok\n",
        "!ngrok authtoken '' # найти его можно https://dashboard.ngrok.com/get-started/setup \n",
        "\n",
        "# Эта команда просто отображет веб морду на другой адрес\n",
        "# Его вы можете найти https://dashboard.ngrok.com/cloud-edge/status\n",
        "# При каждом отключении ссылка будет меняться\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iktP6nMa4f75",
        "outputId": "0bb1fda2-aa9c-448d-a7de-986f86a69d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nohup: redirecting stderr to stdout\n"
          ]
        }
      ],
      "source": [
        "!nohup ngrok http 18273 > /dev/null &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqHe3f_7plbt"
      },
      "source": [
        "После запуска команды выше, перейдите по адресу в ngrok и подождите  пока появится DAG с именем dag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dukXAqmOiz53"
      },
      "source": [
        "### Задача на разработку\n",
        "\n",
        "\n",
        "На прошло шаге мы написали простой пайплайн и обернули его в Airflow. Теперь давайте расширим его возможности с помощью макросов и Xcom. Во всех задачах вам необходимо использовать макрос {{ execution_date }} чтобы данные выгружались за определенный день. Для DAG вам нужно указать даты начала и конца исполнения задач с 2021-01-01 по 2021-01-04.\n",
        "\n",
        "Вам необходимо обернуть ваш код в PythonOperator\n",
        "\n",
        "\n",
        "\n",
        "*   Скачайте валюту за {{ ds }} и положите в Xcom, но не все а только значение\n",
        "*   Скачайте данные за {{ ds }} и положите в БД sqlite (использовать PythonOperator чтобы скачать данные, можно использовать pandas)\n",
        "​\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiivvNDwit9h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "CON = sqlite3.connect('currency.db', isolation_level=None)\n",
        "\n",
        "\n",
        "from airflow import DAG\n",
        "from airflow.utils.dates import days_ago\n",
        "from airflow.operators.email_operator import EmailOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "\n",
        "\n",
        "def extract_data(date, url, tmp_file):\n",
        "    url = f'{url}{date}.csv'\n",
        "    data = pd.read_csv(url).to_csv(tmp_file)\n",
        "    return data\n",
        "\n",
        "def sql_query(sql, conn=CON):\n",
        "  df = None\n",
        "  cursor = conn.cursor()\n",
        "  query = cursor.execute(sql)\n",
        "  if query.description:\n",
        "    df = pd.DataFrame.from_records(data = query.fetchall(), columns = [column[0] for column in query.description])\n",
        "  cursor.close()\n",
        "  return df\n",
        "\n",
        "def load_data(tmp_file, table_name, conn=CON, **context) -> None:\n",
        "    \"\"\" Load to DB\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(tmp_file)# Изменение read_csv\n",
        "    data[\"insert_time\"] = pd.to_datetime(\"now\")\n",
        "    data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "    count = sql_query(f\"select count(*) from '{table_name}'\")\n",
        "    print(f\"Records in table '{table_name}':\", count.values)\n",
        "\n",
        "def extract_currency(date, tmp_file):\n",
        "  url = 'https://api.exchangerate.host/timeseries?start_date=' + str(date) + '&end_date=' + str(date) + \"&base='EUR'\" + \"&symbols=USD\" + '&format=csv'\n",
        "  data = pd.read_csv(url).to_csv(tmp_file)\n",
        "  return data\n",
        "\n",
        "def xcom_data(tmp_file, **kwargs) -> None:\n",
        "    \"\"\" Load to xcom\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(tmp_file)\n",
        "    rate = data[\"rate\"].values\n",
        "    print(f\"Load to x-com:\", rate)\n",
        "    # kwargs['ti'].xcom_push(key='key', value=rate[0])\n",
        "    return rate[0]\n",
        "    \n",
        "\n",
        "with DAG(dag_id='dag',\n",
        "         default_args={'owner': 'airflow'},\n",
        "         schedule_interval='@daily',\n",
        "         start_date= datetime(2021, 1, 1),\n",
        "         end_date=datetime(2021, 1, 4)\n",
        "    ) as dag:\n",
        "\n",
        "    extract_data = PythonOperator(\n",
        "        task_id='extract_data',\n",
        "        python_callable=extract_data,\n",
        "        op_kwargs={'date': '{{ ds }}' ,\n",
        "            'url': 'https://raw.githubusercontent.com/dm-novikov/stepik_airflow_course/main/data_new/',\n",
        "            'tmp_file': '/tmp/file.csv'},\n",
        "        dag=dag\n",
        "    )\n",
        "\n",
        "    load_data = PythonOperator(\n",
        "        task_id='load_data',\n",
        "        python_callable=load_data,\n",
        "        dag=dag,\n",
        "        op_kwargs={\n",
        "            'tmp_file': '/tmp/file.csv',\n",
        "            'table_name': 'currency'\n",
        "        }\n",
        "    )\n",
        "\n",
        "    extract_currency = PythonOperator(\n",
        "        task_id='extract_currency',\n",
        "        python_callable=extract_currency,\n",
        "        op_kwargs={'date': '{{ ds }}' ,\n",
        "            'tmp_file': '/tmp/exchangerate.csv'},\n",
        "        dag=dag\n",
        "    )\n",
        "\n",
        "    xcom_data = PythonOperator(\n",
        "        task_id='xcom_data',\n",
        "        python_callable=xcom_data,\n",
        "        dag=dag,\n",
        "        op_kwargs={\n",
        "            'tmp_file': '/tmp/exchangerate.csv'\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "    extract_data >> load_data\n",
        "    extract_currency >> xcom_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiuYECF5sVSQ",
        "outputId": "9cfb17f0-20f1-4831-bb7b-f179fb57e267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(sqlite3.OperationalError) near \"ДО\": syntax error\n",
            "[SQL: ДО БАЗЫ>]\n",
            "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n",
            " * sqlite:////<ПУТЬ\n",
            "(sqlite3.OperationalError) near \"<\": syntax error\n",
            "[SQL: select * from <ТАБЛИЦА>]\n",
            "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
          ]
        }
      ],
      "source": [
        "# чтобы првоерить решение можете обратиться к вашей базе данных таким образом\n",
        "%load_ext sql\n",
        "%config SqlMagic.feedback=False \n",
        "%config SqlMagic.autopandas=True\n",
        "%sql sqlite:////<ПУТЬ ДО БАЗЫ>\n",
        "%sql select * from <ТАБЛИЦА>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
