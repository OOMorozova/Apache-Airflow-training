{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKVsSmoLVx81"
      },
      "source": [
        "### Настройка окружения\n",
        "\n",
        "Для начала вам необходимо выполнить ряд команд чтобы настроить окружение для дальнейшей работы, это позволит первое время не заниматься долгим деплоем, а сразу начать писать код и работать с airflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHHKEJQSVn9G",
        "outputId": "df5532d9-cf38-4728-b96a-f367c517b3dd"
      },
      "outputs": [],
      "source": [
        "# Установка Airflow\n",
        "!pip install apache-airflow==2.1.4\n",
        "\n",
        "!airflow db init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D_wVrfCzkIG",
        "outputId": "c0924800-51bc-435b-bf2b-abcdf905b9da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/airflow/dags’: File exists\n"
          ]
        }
      ],
      "source": [
        "# Создадим папку dags\n",
        "# В этой папке лежат скрипты для создания дагов\n",
        "# Это стандартное имя для  данной папки\n",
        "!mkdir /root/airflow/dags\n",
        "!touch /root/airflow/dags/dag.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS5E4byhXGDu",
        "outputId": "b2c92017-bade-4c68-f22a-63ff4c3e7592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.10/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.10/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "admin already exist in the db\n"
          ]
        }
      ],
      "source": [
        "!airflow users create \\\n",
        "          --username admin \\\n",
        "          --firstname admin \\\n",
        "          --lastname admin \\\n",
        "          --role Admin \\\n",
        "          --email admin@example.org \\\n",
        "          -p 12345"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEvGbLGh5xum",
        "outputId": "023e8172-6ec7-4b21-a2c8-55fd306d294d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.10/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.10/dist-packages/flask_appbuilder/models/sqla/\u001b[0m\u001b[1;33minterface.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m68\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
            "[\u001b[34m2023-05-09 19:26:42,923\u001b[0m] {\u001b[34mdagbag.py:\u001b[0m496} INFO\u001b[0m - Filling up the DagBag from \u001b[01m/dev/null\u001b[22m\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/airflow\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/airflow/__main__.py\", line 40, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/airflow/cli/cli_parser.py\", line 48, in command\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/airflow/utils/cli.py\", line 92, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/airflow/cli/commands/webserver_command.py\", line 368, in webserver\n",
            "    check_if_pidfile_process_is_running(pid_file=pid_file, process_name=\"webserver\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/airflow/utils/process_utils.py\", line 267, in check_if_pidfile_process_is_running\n",
            "    raise AirflowException(f\"The {process_name} is already running under PID {pid}.\")\n",
            "airflow.exceptions.AirflowException: The webserver is already running under PID 1525.\n"
          ]
        }
      ],
      "source": [
        "# Включим веб-сервер\n",
        "!airflow webserver -p 18273 -D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMdriHrY5yJD",
        "outputId": "819e9b59-aa68-440f-b118-214db75c98b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.10/dist-packages/airflow/utils/\u001b[0m\u001b[1;33mcli.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m149\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'DagRun.serialized_dag'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "\u001b[1;33m/usr/local/lib/python3.10/dist-packages/airflow/utils/\u001b[0m\u001b[1;33mcli.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m149\u001b[0m\u001b[1;33m SAWarning\u001b[0m\u001b[33m: relationship \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m will copy column serialized_dag.dag_id to column dag_run.dag_id, which conflicts with \u001b[0m\u001b[1;33mrelationship\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'DagRun.task_instances'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'TaskInstance.dag_run'\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mcopies task_instance.dag_id to dag_run.dag_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m. If this is not the intention, consider if these relationships should be linked with back_populates, or if \u001b[0m\u001b[33mviewonly\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mTrue\u001b[0m\u001b[33m should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the \u001b[0m\u001b[1;33morm.foreign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter \u001b[0m\u001b[33m'\u001b[0m\u001b[33moverlaps\u001b[0m\u001b[33m=\u001b[0m\u001b[33m\"dag_run\u001b[0m\u001b[33m,task_instances\"'\u001b[0m\u001b[33m to the \u001b[0m\u001b[33m'SerializedDagModel.dag_runs'\u001b[0m\u001b[33m relationship. \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mBackground on this error at: \u001b[0m\u001b[4;33mhttps://sqlalche.me/e/14/qzyx\u001b[0m\u001b[4;33m)\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n"
          ]
        }
      ],
      "source": [
        "# Запуск шедулера\n",
        "!airflow scheduler -D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgEU2eMB5yd9",
        "outputId": "2295fe5a-a9a9-4b82-bf9c-20fd775c7057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "nohup: redirecting stderr to stdout\n"
          ]
        }
      ],
      "source": [
        "# Последующие команды не имеют отношения к Airflow\n",
        "# Они нужни только для корректной работы веб морды\n",
        "# в среде Google Colab\n",
        "\n",
        "!pip install pyngrok\n",
        "!ngrok authtoken  # найти его можно https://dashboard.ngrok.com/get-started/setup \n",
        "\n",
        "# Эта команда просто отображет веб морду на другой адрес\n",
        "# Его вы можете найти https://dashboard.ngrok.com/cloud-edge/status\n",
        "# При каждом отключении ссылка будет меняться\n",
        "!nohup ngrok http 18273 > /dev/null &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYtYIZutPFOv"
      },
      "source": [
        "### Задача на разработку\n",
        "\n",
        "Необходимо реализовать \n",
        "\n",
        "- Сенсор который будет возвращать True с вероятностью 0.3 и False с 0.7.\n",
        "- Написать автогенерацию тасков сенсеров из прошлого пункта, 3 штуки, должны запускаться параллельно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5RZSvfnAPHHk"
      },
      "outputs": [],
      "source": [
        "## ВАШЕ РЕШЕНИЕ\n",
        "from airflow.sensors.base import BaseSensorOperator\n",
        "from airflow import DAG\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from airflow.utils.dates import days_ago\n",
        "\n",
        "\n",
        "class CustomSensor(BaseSensorOperator):\n",
        "\n",
        "    def poke(self, context):\n",
        "        return_value = np.random.binomial(1, 0.3)\n",
        "        return bool(return_value)\n",
        "\n",
        "dag = DAG('dag',schedule_interval=timedelta(days=1), start_date=days_ago(1))\n",
        "args = {\n",
        "    \"poke_interval\": 4,\n",
        "    \"timeout\": 50,\n",
        "    \"mode\": \"reschedule\",\n",
        "    \"soft_fail\": True\n",
        "}\n",
        "\n",
        "tasks_list=list()\n",
        "for i in range(0, 3):\n",
        "    tasks_list.append(CustomSensor(task_id=f'task_{i}', dag=dag, **args))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
